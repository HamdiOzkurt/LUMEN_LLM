# LLM Dashboard Backend - Merkezi LLM Ä°zleme ve Maliyet YÃ¶netimi

<img width="1919" height="900" alt="image" src="https://github.com/user-attachments/assets/5ae9b4e7-3323-4a4d-985b-05d19cf04d70" />
<img width="1919" height="909" alt="image" src="https://github.com/user-attachments/assets/1c28d897-b1de-4f18-a8a0-b15f59f25e05" />

Yapay Zeka (LLM) operasyonlarÄ±nÄ±zÄ±n kalbi: KullanÄ±m oranlarÄ±nÄ±, model maliyetlerini ve performans metriklerini tek bir merkezden izleyin.

## Proje HakkÄ±nda

Bu proje, modern uygulamalarÄ±n vazgeÃ§ilmezi haline gelen BÃ¼yÃ¼k Dil Modelleri (LLM - Ã¶rn. GPT-4, Gemini, Claude) entegrasyonlarÄ± iÃ§in geliÅŸmiÅŸ bir izleme (monitoring) ve gÃ¶zlemlenebilirlik (observability) Ã§Ã¶zÃ¼mÃ¼dÃ¼r. UygulamalarÄ±nÄ±zÄ±n LLM saÄŸlayÄ±cÄ±larÄ±yla olan tÃ¼m trafiÄŸini kayÄ±t altÄ±na alarak; maliyet analizi, performans darboÄŸazlarÄ±nÄ±n tespiti ve kullanÄ±m alÄ±ÅŸkanlÄ±klarÄ±nÄ±n detaylÄ± raporlanmasÄ±nÄ± saÄŸlar.

Bu backend servisi, verileri toplar, iÅŸler ve gÃ¶rselleÅŸtirme araÃ§larÄ± (frontend dashboard) iÃ§in hazÄ±r hale getirir. TÃ¼m LLM operasyonlarÄ±nÄ± tek bir noktadan yÃ¶netmek isteyen geliÅŸtirici ekipleri ve organizasyonlar iÃ§in tasarlanmÄ±ÅŸtÄ±r.

## Proje YapÄ±sÄ±

```text
llm_dashboard/
â”œâ”€â”€ frontend/             # Ã–n yÃ¼z uygulamasÄ± (React/Vite)
â”œâ”€â”€ llm-monitor-sdk/      # SDK kÃ¼tÃ¼phanesi
â”œâ”€â”€ server/               # Sunucu kaynak dosyalarÄ± (TS)
â”œâ”€â”€ shared/               # PaylaÅŸÄ±lan veri tipleri ve sabitler
â”œâ”€â”€ src/                  # Backend uygulama dosyalarÄ± (JS)
â”‚   â”œâ”€â”€ models/           # VeritabanÄ± ÅŸemalarÄ± ve modelleri
â”‚   â”œâ”€â”€ routes/           # API endpoint tanÄ±mlarÄ±
â”‚   â””â”€â”€ server.js         # Ana sunucu dosyasÄ±
â”œâ”€â”€ package.json          # Proje konfigÃ¼rasyonu ve baÄŸÄ±mlÄ±lÄ±klar
â””â”€â”€ README.md             # DokÃ¼mantasyon
```

## Temel Ã–zellikler

- **Session BazlÄ± Ä°zleme:** ğŸ†• KonuÅŸma oturumlarÄ±nÄ± grupla, kullanÄ±cÄ± davranÄ±ÅŸlarÄ±nÄ± analiz et. Her mesajÄ± ayrÄ± deÄŸil, anlamlÄ± konuÅŸmalar olarak takip et.
- **DetaylÄ± Maliyet Analizi:** Proje, saÄŸlayÄ±cÄ± (OpenAI, Google vb.) ve model bazlÄ± harcamalarÄ±nÄ±zÄ± gerÃ§ek zamanlÄ± takip edin. Hangi Ã¶zelliÄŸin ne kadar maliyet oluÅŸturduÄŸunu net bir ÅŸekilde gÃ¶rÃ¼n.
- **Performans ve Latency Takibi:** Ä°steklerin yanÄ±t sÃ¼relerini izleyin, yavaÅŸlayan modelleri veya anormal gecikmeleri anÄ±nda tespit ederek kullanÄ±cÄ± deneyimini iyileÅŸtirin.
- **Token KullanÄ±m Ä°statistikleri:** Prompt (girdi) ve Completion (Ã§Ä±ktÄ±) token sayÄ±larÄ±nÄ± ayrÄ±ÅŸtÄ±rarak model kullanÄ±m yoÄŸunluÄŸunu analiz edin.
- **Hata ve GÃ¼venilirlik Ä°zleme:** API hatalarÄ±nÄ±, timeout durumlarÄ±nÄ± ve baÅŸarÄ±sÄ±z istekleri yakalayarak sisteminizin stabilitesini koruyun.
- **GerÃ§ek ZamanlÄ± AkÄ±ÅŸ:** WebSocket desteÄŸi sayesinde gerÃ§ekleÅŸen LLM Ã§aÄŸrÄ±larÄ±nÄ± anlÄ±k olarak dashboard Ã¼zerinden izleyin.

## Kurulum (NPM ile)

Bu projeyi Node.js uygulamalarÄ±nÄ±za entegre etmek veya servisi sunucunuzda Ã§alÄ±ÅŸtÄ±rmak iÃ§in NPM paket yÃ¶neticisini kullanabilirsiniz.

[![NPM Version](https://img.shields.io/npm/v/@hamdi_ozkurt/llm-dashboard-backend)](https://www.npmjs.com/package/@hamdi_ozkurt/llm-dashboard-backend)
[![NPM Profile](https://img.shields.io/badge/NPM-Profile-red)](https://www.npmjs.com/~hamdi_ozkurt)

```bash
npm install @hamdi_ozkurt/llm-dashboard-backend
```

**FaydalÄ± Linkler:**

- [NPM Paketi](https://www.npmjs.com/package/@hamdi_ozkurt/llm-dashboard-backend)
- [GeliÅŸtirici NPM Profili](https://www.npmjs.com/~hamdi_ozkurt)

## YapÄ±landÄ±rma ve BaÅŸlatma

Kurulumdan sonra servisi ayaÄŸa kaldÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin.

### 1. VeritabanÄ± BaÄŸlantÄ±sÄ±

Uygulama, verileri saklamak iÃ§in **MongoDB** kullanÄ±r. Yerel bilgisayarÄ±nÄ±zda veya bulutta (MongoDB Atlas) Ã§alÄ±ÅŸan bir MongoDB baÄŸlantÄ± adresine ihtiyacÄ±nÄ±z vardÄ±r.

```bash
# Windows (MongoDB Community kurulu ise)
net start MongoDB
```

### 2. Ortam DeÄŸiÅŸkenleri (.env)

Proje kÃ¶k dizininde bir `.env` dosyasÄ± oluÅŸturun ve aÅŸaÄŸÄ±daki ayarlarÄ± yapÄ±n:

```env
PORT=3000
MONGODB_URI=mongodb://localhost:27017/llm_dashboard
NODE_ENV=production
GEMINI_API_KEY=your_gemini_api_key_here
```

### 3. Servisi BaÅŸlatma

```bash
# GeliÅŸtirme modu
npm run dev

# CanlÄ± ortam (Production)
npm start
```

## ğŸ†• Session BazlÄ± Ä°zleme Sistemi

Session sistemi, her LLM Ã§aÄŸrÄ±sÄ±nÄ± baÄŸÄ±msÄ±z log olarak deÄŸil, **anlamlÄ± konuÅŸma oturumlarÄ±** olarak gruplar.

### FaydalarÄ±

- âœ… **KonuÅŸma BaÄŸlamÄ±:** Hangi mesajlarÄ±n aynÄ± konuÅŸmaya ait olduÄŸunu gÃ¶rÃ¼n
- âœ… **KullanÄ±cÄ± Analizi:** Ortalama mesaj sayÄ±sÄ±, konuÅŸma sÃ¼resi, kullanÄ±cÄ± davranÄ±ÅŸlarÄ±
- âœ… **Maliyet Optimizasyonu:** Session bazÄ±nda maliyet analizi ($0.03/session)
- âœ… **Performans Ä°zleme:** Session bazÄ±nda toplam sÃ¼re ve yanÄ±t sÃ¼releri
- âœ… **Debugging:** TÃ¼m konuÅŸma geÃ§miÅŸini bir arada gÃ¶rÃ¼n

### ğŸ¯ Neden User ID KullanmalÄ±sÄ±nÄ±z? (GeliÅŸtiriciler Ä°Ã§in)

Bu sistemin en gÃ¼Ã§lÃ¼ yanÄ±, `userId` parametresi ile saÄŸladÄ±ÄŸÄ± **kiÅŸiselleÅŸtirilmiÅŸ izleme yeteneÄŸidir**. Kendi projenizdeki kullanÄ±cÄ±larÄ±n (son kullanÄ±cÄ±larÄ±n) ID'lerini SDK'ya ileterek ÅŸunlarÄ± kazanÄ±sÄ±nÄ±z:

1.  **ğŸ•µï¸â€â™‚ï¸ MÃ¼vekkil/MÃ¼ÅŸteri BazlÄ± Debugging:**
    MÃ¼ÅŸteriniz "Botunuz bana yanlÄ±ÅŸ cevap verdi" dediÄŸinde, Dashboard'a girip o mÃ¼ÅŸterinin `userId`'sini aratarak, yaÅŸadÄ±ÄŸÄ± tÃ¼m konuÅŸma geÃ§miÅŸini ve hatanÄ±n kaynaÄŸÄ±nÄ± (Prompt mu, Model mi?) saniyeler iÃ§inde gÃ¶rebilirsiniz.

2.  **ğŸ’° Maliyetin Sorumlusunu Bulma:**
    "API kotam neden hemen bitti?" sorusunun cevabÄ± artÄ±k gizli deÄŸil. Hangi kullanÄ±cÄ±nÄ±zÄ±n veya departmanÄ±nÄ±zÄ±n sistemi en Ã§ok kullandÄ±ÄŸÄ±nÄ± ve ne kadar maliyet oluÅŸturduÄŸunu tek tÄ±kla tespit edin.

3.  **ğŸ›¡ï¸ Bot ve KÃ¶tÃ¼ Niyetli KullanÄ±m Tespiti:**
    OlaÄŸandÄ±ÅŸÄ± aktivite gÃ¶steren bir `userId` tespit ettiÄŸinizde, sisteminize zarar gelmeden o kullanÄ±cÄ±yÄ± izleyebilir ve Ã¶nlem alabilirsiniz.

> **Ã–zet:** `userId` olmadan bu sadece bir sayaÃ§tÄ±r; `userId` ile ise **profesyonel bir mÃ¼ÅŸteri destek ve analiz aracÄ±dÄ±r.**

### KullanÄ±m Ã–rneÄŸi (Gemini)

```javascript
import { GeminiProvider } from '@llm-dashboard/monitor-sdk';
import { v4 as uuidv4 } from 'uuid';

// Session ID oluÅŸtur
const sessionId = `session-${uuidv4()}`;

// Provider'Ä± session bilgisi ile baÅŸlat
const llm = new GeminiProvider({
  apiKey: process.env.GEMINI_API_KEY,
  backendUrl: 'http://localhost:3000/api',
  projectId: 'my-chatbot',
  sessionId: sessionId,     // Session ID
  userId: 'user-123',       // KullanÄ±cÄ± ID
  debug: true
});

// Ä°lk mesaj
const response1 = await llm.generateContent({
  model: 'gemini-2.5-flash',
  prompt: 'Merhaba! Yapay zeka nedir?',
  temperature: 0.7,
  maxOutputTokens: 100
});

// Ä°kinci mesaj (aynÄ± session)
const response2 = await llm.generateContent({
  model: 'gemini-2.5-flash',
  prompt: 'KullanÄ±m alanlarÄ± nelerdir?',
  temperature: 0.7,
  maxOutputTokens: 100
});

// Session'Ä± tamamla
await axios.patch(`http://localhost:3000/api/sessions/${sessionId}/complete`);
```

### Test Etme

```bash
# Session sistemini test et
node test-session.js
```

## Entegrasyon ve API KullanÄ±mÄ±

Sistemin verileri analiz edebilmesi iÃ§in, client veya server tarafÄ±ndaki uygulamalarÄ±nÄ±zÄ±n yaptÄ±ÄŸÄ± LLM Ã§aÄŸrÄ±larÄ±nÄ± bu backend servisine iletmesi gerekmektedir.

### API Endpoints

Bu servis, verileri toplamak ve raporlamak iÃ§in aÅŸaÄŸÄ±daki ana eriÅŸim noktalarÄ±nÄ± sunar:

- **POST /api/logs** - LLM Ã§aÄŸrÄ±sÄ± kaydÄ±
- **GET /api/logs** - Log listesi (filtreleme)
- **GET /api/metrics** - Maliyet ve performans metrikleri
- **POST /api/sessions** - Yeni session oluÅŸtur
- **POST /api/sessions/:id/messages** - Session'a mesaj ekle
- **GET /api/sessions** - Session listesi
- **GET /api/sessions/:id** - Session detaylarÄ±
- **PATCH /api/sessions/:id/complete** - Session'Ä± tamamla
- **GET /api/sessions/stats/summary** - Session istatistikleri

## GerÃ§ek ZamanlÄ± Ä°zleme (WebSocket)

Panel Ã¼zerindeki veriler canlÄ± olarak akar.

```javascript
const socket = io("http://localhost:3000");

// Yeni log bildirimi
socket.on("new-log", (log) => {
  console.log("Yeni LLM kullanÄ±mÄ±:", log);
});

// Session gÃ¼ncellemesi
socket.on("session-updated", (session) => {
  console.log("Session gÃ¼ncellendi:", session);
});
```

## Dashboard GÃ¶rÃ¼nÃ¼mleri

- **ğŸ“Š Dashboard:** Genel bakÄ±ÅŸ ve metrikler
- **ğŸ“ Requests:** TÃ¼m LLM Ã§aÄŸrÄ±larÄ±
- **ğŸ¤– Models:** Model bazlÄ± analiz
- **ğŸ’¬ Sessions:** KonuÅŸma oturumlarÄ± (YENÄ°!)
- **ğŸ“ˆ Analytics:** DetaylÄ± analizler
- **âš™ï¸ Settings:** Ayarlar ve yapÄ±landÄ±rma

## Lisans

ISC
